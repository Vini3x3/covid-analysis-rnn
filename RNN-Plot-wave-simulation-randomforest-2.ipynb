{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2693e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from loader.DataLoader import read_dataframe\n",
    "from loader.DataTransformer import lag_list, transform_matrix\n",
    "\n",
    "from model.RandomForestLstmModel import RandomForestLstmModel\n",
    "from model.ScalingResidualLstmModel import ScalingResidualLstmModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b21ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c32726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data parameter\n",
    "LAG = 15\n",
    "WAVE = 4\n",
    "REPEAT = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddfc183",
   "metadata": {},
   "source": [
    "### Emsemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff86b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_path(wave: int, filename: str)-> str:\n",
    "    curr_dir = os.getcwd()\n",
    "    project_dir = curr_dir.split('GitHub')[0]\n",
    "    analysis_on_covid_dir = os.path.join(project_dir, 'GitHub', 'analysis-on-covid')\n",
    "    return analysis_on_covid_dir + 'checkpoint_wave' + str(wave) + '/' + filename\n",
    "    # return 'checkpoint_wave' + str(wave) + '/' + filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9a4f2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = np.load(get_file_path(WAVE, 'best_train_loss.npy'))\n",
    "\n",
    "# build model\n",
    "input_dim = 22\n",
    "hidden_dim = 64\n",
    "num_layers = 4\n",
    "output_dim = 1\n",
    "\n",
    "models = []\n",
    "for i in range(REPEAT):\n",
    "    model = ScalingResidualLstmModel(input_dim, hidden_dim, num_layers, output_dim, LAG)\n",
    "    model_path: str = get_file_path(WAVE, 'checkpoints/model_{:02d}.chk'.format(i))\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    models.append(copy.deepcopy(model))\n",
    "\n",
    "model = RandomForestLstmModel(models, performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6884e60d",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6a25bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothse(dataframe: pd.DataFrame):\n",
    "    \n",
    "    policies = ['school', 'no_hong_kong_p',\n",
    "       'hong_kong_group', 'hong_kong_all', 'home_other_14', 'home_21',\n",
    "       'home_14', 'home_7', 'home_3', 'type_1_close', 'type_2_close',\n",
    "       'type_3_close', 'people2', 'people4', 'people8', '0500_1800',\n",
    "       '0500_2200', '0500_0200']\n",
    "    for policy in policies:\n",
    "        dataframe.loc[:, policy] = 0\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8016a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wave_period(wave: int):\n",
    "    if wave == 1:\n",
    "        return (52, 103)\n",
    "    elif wave == 2:\n",
    "        return (160, 280)\n",
    "    elif wave == 3:\n",
    "        return (280, 505)\n",
    "    elif wave == 4:\n",
    "        return (757, 871)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44ce2653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_column(df: pd.DataFrame, column_name: str)->pd.DataFrame:\n",
    "    if (df[column_name] == 0).all():\n",
    "        return df[column_name]\n",
    "    return (df[column_name] - df[column_name].mean()) / df[column_name].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "247907e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_z_norm_count(df: pd.DataFrame, wave:int, lag:int):\n",
    "    wave_start, wave_end = get_wave_period(WAVE)\n",
    "    _ = df[wave_start - lag: wave_end]\n",
    "    return (_['count'].mean(), _['count'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "008cabbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(sequence: pd.DataFrame, wave: int, lag: int):    \n",
    "    # prepare data\n",
    "    wave_start, wave_end = get_wave_period(WAVE)\n",
    "    sequence = sequence[wave_start - LAG: wave_end]\n",
    "\n",
    "    for _ in ['avg_temp', 'avg_humid', 'sum', 'count']:\n",
    "        sequence.loc[:, _] = std_column(sequence, _)\n",
    "\n",
    "    shifted_sequence = lag_list(sequence, LAG + 1)  # shift into delayed sequences\n",
    "\n",
    "    x_train = shifted_sequence[:, :-1, 1:]  # for each delayed sequence, take all elements except last element\n",
    "    y_train = shifted_sequence[:, -1, -1]  # for each delayed sequence, only take the last element\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "    x_train = torch.from_numpy(x_train.astype('float64')).type(torch.Tensor)  # convert to tensor\n",
    "    y_train = torch.from_numpy(y_train.astype('float64')).type(torch.Tensor)  # convert to tensor\n",
    "    \n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d1b69e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(x_train, model, lag:int):\n",
    "    # for the first day's input, the prediction is real.  \n",
    "    # that is to kickstart the ongoing prediction\n",
    "    x_test = x_train[0].reshape(1,lag, x_train.shape[2]) # get the first input\n",
    "    y_pred = [ x_test[0][-1][0].detach().numpy().reshape(-1) ] # initialize the list with the first actual count\n",
    "\n",
    "    prediction_range = len(x_train)\n",
    "\n",
    "    for i in range(1, prediction_range):\n",
    "        _ = model(x_test)\n",
    "\n",
    "        # extract the next input item\n",
    "        x_test = x_train[i].reshape(1, LAG, x_train.shape[2])\n",
    "\n",
    "        # append to model prediction list\n",
    "        _2 = _.detach().numpy()  # revert from tensor\n",
    "        _2 = _2.reshape(-1)  # reshape back to normal list\n",
    "        y_pred.append(_2)\n",
    "        \n",
    "        # modify the previous day's count to be the prediction\n",
    "        for j in range(min(len(y_pred), lag)):\n",
    "            x_test[0][-(j+1)][0] = torch.tensor(y_pred[-(j+1)])\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cdfec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse(y_pred: np.ndarray, y_true: np.ndarray)-> float:\n",
    "    return sum((y_pred - y_true) ** 2) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9e5b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(y_pred: np.ndarray, y_true: np.ndarray)-> float:\n",
    "    return sum((y_pred - y_true) ** 2) / len(y_true) / np.var(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cff5a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "df_ori = read_dataframe('all')\n",
    "count_mean, count_std = get_z_norm_count(df_ori, WAVE, LAG)\n",
    "x_ori, y_train = transform_data(df_ori, WAVE, LAG)\n",
    "\n",
    "df_mod = hypothse(read_dataframe('all'))\n",
    "x_mod, _ = transform_data(df_mod, WAVE, LAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9943ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_baseline = simulation(x_ori, model, LAG)\n",
    "y_pred_simulate = simulation(x_mod, model, LAG)\n",
    "\n",
    "# reshape back to normal list\n",
    "y_pred_baseline = np.array(y_pred_baseline).reshape(-1)  \n",
    "y_pred_simulate = np.array(y_pred_simulate).reshape(-1)\n",
    "y_train = np.array(y_train).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0395344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE | MSE: 6.31E-01 | RMSE: 5.80E-01\n",
      "SIMULATE | MSE: 5.28E-01 | RMSE: 4.86E-01\n"
     ]
    }
   ],
   "source": [
    "mse_baseline = get_mse(y_pred_baseline, y_train)\n",
    "rmse_baseline = get_rmse(y_pred_baseline, y_train)\n",
    "print(\"BASELINE | MSE: %.2E | RMSE: %.2E\" % (mse_baseline, rmse_baseline))\n",
    "\n",
    "mse_simulate = get_mse(y_pred_simulate, y_train)\n",
    "rmse_simulate = get_rmse(y_pred_simulate, y_train)\n",
    "print(\"SIMULATE | MSE: %.2E | RMSE: %.2E\" % (mse_simulate, rmse_simulate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6129a95a",
   "metadata": {},
   "source": [
    "### Plot Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "914582f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(len(y_train)), y_train, color='black', label='actual')\n",
    "# plt.plot(range(len(y_pred_baseline)), y_pred_baseline, 'r--', label='baseline (rmse={rmse:.2e})'.format(rmse=rmse_baseline))\n",
    "# plt.plot(range(len(y_pred_simulate)), y_pred_simulate, 'g--', label='simulate (rmse={rmse:.2e})'.format(rmse=rmse_simulate))\n",
    "# plt.ylabel(\"count\")\n",
    "# plt.xlabel(\"day\")\n",
    "# plt.title(\"WAVE %d simulation (without adjustment)\" % (WAVE + 1))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1b5b7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adjustment factor 0.66\n"
     ]
    }
   ],
   "source": [
    "# adjustment for accumulated data\n",
    "adjustment_factor = 1 - rmse_baseline**2\n",
    "# y_pred_baseline *= adjustment_factor\n",
    "# y_pred_simulate *= adjustment_factor\n",
    "print(\"adjustment factor %.2f\" % adjustment_factor)\n",
    "\n",
    "# de-normalization\n",
    "y_pred_baseline = y_pred_baseline * count_std + count_mean\n",
    "y_pred_simulate = y_pred_simulate * count_std + count_mean\n",
    "y_train = y_train * count_std + count_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0efbf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(len(y_train)), y_train, color='black', label='actual')\n",
    "# plt.plot(range(len(y_pred_baseline)), y_pred_baseline, 'r--', label='baseline (rmse={rmse:.2e})'.format(rmse=rmse_baseline))\n",
    "# plt.plot(range(len(y_pred_simulate)), y_pred_simulate, 'g--', label='simulate (rmse={rmse:.2e})'.format(rmse=rmse_simulate))\n",
    "# plt.ylabel(\"count\")\n",
    "# plt.xlabel(\"day\")\n",
    "# plt.title(\"WAVE %d simulation\" % (WAVE+1))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a93d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
