{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2693e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from loader.DataLoader import read_dataframe\n",
    "from loader.DataTransformer import lag_list, transform_matrix\n",
    "from model.CnnLstmModel import CnnLstmModel\n",
    "from model.FcLstmModel import FcLstmModel\n",
    "from model.LstmModel import LstmModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b21ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c32726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data parameter\n",
    "LAG = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffdba3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "sequence = read_dataframe('all').to_numpy()\n",
    "sequence = sequence[:, 1:]\n",
    "# sequence = transform_matrix(sequence, 'DIFF')\n",
    "sequence = transform_matrix(sequence, 'NORM')\n",
    "# sequence[np.isnan(sequence)] = 0 # fill na - there is a column which are all 0\n",
    "\n",
    "shifted_sequence = lag_list(sequence, LAG + 1)  # shift into delayed sequences\n",
    "\n",
    "x_train = shifted_sequence[:, :-1, 1:]  # for each delayed sequence, take all elements except last element\n",
    "y_train = shifted_sequence[:, -1, -1]  # for each delayed sequence, only take the last element\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "x_train = torch.from_numpy(x_train.astype('float64')).type(torch.Tensor)  # convert to tensor\n",
    "y_train = torch.from_numpy(y_train.astype('float64')).type(torch.Tensor)  # convert to tensor\n",
    "\n",
    "wave_1_x, wave_1_y = x_train[52 -LAG:103 -LAG], y_train[52 -LAG:103 -LAG]\n",
    "wave_2_x, wave_2_y = x_train[160 -LAG:280 -LAG], y_train[160 -LAG:280 -LAG]\n",
    "wave_3_x, wave_3_y = x_train[280 -LAG:505 -LAG], y_train[280 -LAG:505 -LAG]\n",
    "wave_4_x, wave_4_y = x_train[716 -LAG:738 -LAG], y_train[716 -LAG:738 -LAG]\n",
    "\n",
    "wave_x, wave_y = wave_4_x, wave_4_y\n",
    "TRAIN_RANGE = int(np.floor(wave_y.shape[0] * 4 / 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556a86a0",
   "metadata": {},
   "source": [
    "### Main Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfe7167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_vis(input_x, input_y, train_range, model, learning_rate=1e-5, num_epochs=3_000):\n",
    "    # train\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    # loss_fn = torch.nn.L1Loss()\n",
    "    # loss_fn = torch.nn.SmoothL1Loss()\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    min_loss = np.inf\n",
    "    best_model_state = None\n",
    "    model.train()\n",
    "    y_var = np.var(input_y.numpy().reshape(-1)[:train_range])\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        y_pred = model(input_x[:train_range])\n",
    "        loss = loss_fn(y_pred, input_y[:train_range])\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch: %d | MSE: %.2E | RRSE: %.2E\" % (epoch, loss.item(), np.sqrt(loss.item() / y_var)))\n",
    "        if min_loss > loss.item():\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            min_loss = loss.item()\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "    model.eval()\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "    x_test = input_x[train_range].reshape(1, LAG, input_x.shape[2])\n",
    "    y_pred = []\n",
    "    prediction_range = input_x.shape[0] - train_range\n",
    "    # prediction_range = 7\n",
    "    for i in range(prediction_range):\n",
    "        _ = model(x_test)\n",
    "        x_test = input_x[train_range + i].reshape(1, LAG, input_x.shape[2])\n",
    "        x_test[0][-1][0] = torch.tensor(_.item())\n",
    "        _2 = _.detach().numpy()  # revert from tensor\n",
    "        _2 = _2.reshape(-1)  # reshape back to normal list\n",
    "        y_pred.append(_2)\n",
    "\n",
    "    y_pred = np.array(y_pred).reshape(-1)  # reshape back to normal list\n",
    "    print(\"sample prediction:  \", y_pred)\n",
    "\n",
    "    y_train_sample = input_y[train_range:].detach().numpy().reshape(-1)[:prediction_range]\n",
    "    print(\"sample true result: \", y_train_sample)\n",
    "\n",
    "    mse = sum((y_train_sample - y_pred) ** 2) / len(y_pred)\n",
    "    rmse = mse / np.var(y_train_sample)\n",
    "    print(\"TEST | MSE: %.2E | RRSE: %.2E\" % (mse, rmse))\n",
    "    return mse, rmse, y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8430a2c1",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eae5cc11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ab97e07",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model_fclstm = FcLstmModel(input_dim, 128, 3, 1, LAG, 0.1, 0)\n",
    "# mse_fclstm, rmse_fclstm, y_pred_fclstm =  train_test_vis(wave_x, wave_y, TRAIN_RANGE, model_fclstm, learning_rate=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8d51b30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model_cnnlstm = CnnLstmModel(input_dim, LAG + 1)\n",
    "# mse_cnnlstm, rmse_cnnlstm, y_pred_cnnlstm =  train_test_vis(wave_x, wave_y, TRAIN_RANGE, model_cnnlstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "721eb196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_lstm = LstmModel(input_dim, 128, 3, 1)\n",
    "# mse_lstm, rmse_lstm, y_pred_lstm = train_test_vis(wave_x, wave_y, TRAIN_RANGE, model_lstm, learning_rate=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22d2fff",
   "metadata": {},
   "source": [
    "### Plot Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "632aa839",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# y_given = wave_y.detach().numpy().reshape(-1)\n",
    "# plt.plot(range(len(y_given)), y_given, color='black')\n",
    "# plt.plot(range(TRAIN_RANGE, len(y_given)), y_pred_lstm, 'b--', label='lstm (mse={mse:.2e})'.format(mse=mse_lstm))\n",
    "# plt.plot(range(TRAIN_RANGE, len(y_given)), y_pred_cnnlstm, 'g--', label='cnnlstm (mse={mse:.2e})'.format(mse=mse_cnnlstm))\n",
    "# plt.plot(range(TRAIN_RANGE, len(y_given)), y_pred_fclstm, 'y--', label='fclstm (mse={mse:.2e})'.format(mse=mse_fclstm))\n",
    "# plt.axvline(x=TRAIN_RANGE, linestyle='--', color='red')\n",
    "# plt.ylabel(\"count\")\n",
    "# plt.xlabel(\"day\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddd1798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(seq, seq_min, seq_max):\n",
    "    return seq * (seq_max - seq_min) + seq_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8a6ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_min, overall_max = 0, 56827\n",
    "\n",
    "# y_given_ = denorm(y_given, overall_min, overall_max)\n",
    "# y_pred_lstm_ = denorm(y_pred_lstm, overall_min, overall_max)\n",
    "# y_pred_cnnlstm_ = denorm(y_pred_cnnlstm, overall_min, overall_max)\n",
    "# y_pred_fclstm_ = denorm(y_pred_fclstm, overall_min, overall_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ea5aae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(len(y_given_)), y_given_, color='black')\n",
    "# plt.plot(range(TRAIN_RANGE, len(y_given_)), y_pred_lstm_, 'b--', label='lstm (rmse={rmse:.2e})'.format(rmse=rmse_lstm))\n",
    "# plt.plot(range(TRAIN_RANGE, len(y_given_)), y_pred_cnnlstm_, 'g--', label='cnnlstm (rmse={rmse:.2e})'.format(rmse=rmse_cnnlstm))\n",
    "# plt.plot(range(TRAIN_RANGE, len(y_given_)), y_pred_fclstm_, 'y--', label='fclstm (rmse={rmse:.2e})'.format(rmse=rmse_fclstm))\n",
    "# plt.axvline(x=TRAIN_RANGE, linestyle='--', color='red')\n",
    "# plt.ylabel(\"count\")\n",
    "# plt.xlabel(\"day\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c9a28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
