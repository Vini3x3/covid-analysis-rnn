{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "118718f9-5d2e-468b-824b-6ce362b603b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from loader.DataLoader import read_sequence, read_dataframe\n",
    "from loader.DataTransformer import lag_list, moving_average\n",
    "from model.Attention_LstmModel import Attention_LstmModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e2d97f1-bd75-4f8d-9879-c849a809cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script parameter\n",
    "# MODE: MA (moving average), D1(lag 1 degree), DMA(decaying moving average) or default no change\n",
    "# MODE = 'MA'\n",
    "LAG = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e54bb1f-6fe1-4932-bf6e-5fd5d4eee395",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare data\n",
    "sequence = read_dataframe('all').to_numpy()\n",
    "y_var = np.var(sequence[:,-1])\n",
    "shifted_sequence = lag_list(sequence, LAG)  # shift into delayed sequences\n",
    "\n",
    "x_train = shifted_sequence[:, :-1, 1:]  # for each delayed sequence, take all elements except last element\n",
    "y_train = shifted_sequence[:, -1, -1]  # for each delayed sequence, only take the last element\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "x_train = torch.from_numpy(x_train.astype('float64')).type(torch.Tensor)  # convert to tensor\n",
    "y_train = torch.from_numpy(y_train.astype('int32')).type(torch.Tensor)  # convert to tensor\n",
    "\n",
    "# build model\n",
    "input_dim = x_train.shape[-1]\n",
    "hidden_dim = 64\n",
    "num_layers = 2\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25ca354b-4f20-4521-833c-220d81541df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 | MSE: 2.05E+07 | RRSE: 1.03E+00\n",
      "Epoch: 200 | MSE: 2.04E+07 | RRSE: 1.03E+00\n",
      "Epoch: 300 | MSE: 2.03E+07 | RRSE: 1.03E+00\n",
      "Epoch: 400 | MSE: 2.02E+07 | RRSE: 1.02E+00\n",
      "Epoch: 500 | MSE: 2.01E+07 | RRSE: 1.02E+00\n",
      "Epoch: 600 | MSE: 2.00E+07 | RRSE: 1.02E+00\n",
      "Epoch: 700 | MSE: 1.99E+07 | RRSE: 1.02E+00\n",
      "Epoch: 800 | MSE: 1.98E+07 | RRSE: 1.01E+00\n",
      "Epoch: 900 | MSE: 1.97E+07 | RRSE: 1.01E+00\n",
      "Epoch: 1000 | MSE: 1.96E+07 | RRSE: 1.01E+00\n",
      "Epoch: 1100 | MSE: 1.95E+07 | RRSE: 1.01E+00\n",
      "Epoch: 1200 | MSE: 1.95E+07 | RRSE: 1.01E+00\n",
      "Epoch: 1300 | MSE: 1.94E+07 | RRSE: 1.01E+00\n",
      "Epoch: 1400 | MSE: 1.94E+07 | RRSE: 1.00E+00\n",
      "Epoch: 1500 | MSE: 1.93E+07 | RRSE: 1.00E+00\n",
      "Epoch: 1600 | MSE: 1.92E+07 | RRSE: 1.00E+00\n",
      "Epoch: 1700 | MSE: 1.92E+07 | RRSE: 1.00E+00\n",
      "Epoch: 1800 | MSE: 1.92E+07 | RRSE: 9.98E-01\n",
      "Epoch: 1900 | MSE: 1.91E+07 | RRSE: 9.97E-01\n",
      "Epoch: 2000 | MSE: 1.91E+07 | RRSE: 9.96E-01\n",
      "Epoch: 2100 | MSE: 1.90E+07 | RRSE: 9.94E-01\n",
      "Epoch: 2200 | MSE: 1.91E+07 | RRSE: 9.97E-01\n",
      "Epoch: 2300 | MSE: 1.90E+07 | RRSE: 9.94E-01\n",
      "Epoch: 2400 | MSE: 1.89E+07 | RRSE: 9.91E-01\n",
      "Epoch: 2500 | MSE: 1.88E+07 | RRSE: 9.89E-01\n",
      "Epoch: 2600 | MSE: 1.87E+07 | RRSE: 9.88E-01\n",
      "Epoch: 2700 | MSE: 1.87E+07 | RRSE: 9.86E-01\n",
      "Epoch: 2800 | MSE: 1.86E+07 | RRSE: 9.84E-01\n",
      "Epoch: 2900 | MSE: 1.85E+07 | RRSE: 9.82E-01\n",
      "Epoch: 3000 | MSE: 1.85E+07 | RRSE: 9.80E-01\n",
      "sample prediction:   [2.3441563 1.2307396 1.2302055 1.2316914 1.2278042]\n",
      "sample true result:  [2. 3. 0. 3. 0.]\n"
     ]
    }
   ],
   "source": [
    "model = Attention_LstmModel(input_dim, hidden_dim, num_layers, output_dim)\n",
    "\n",
    "# train\n",
    "num_epochs = 3_000 # 3_000\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "model.train()\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    y_pred = model(x_train)[0]\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: %d | MSE: %.2E | RRSE: %.2E\" % (epoch, loss.item(), np.sqrt(loss.item() / y_var)))\n",
    "    optimiser.zero_grad()\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "\n",
    "# test\n",
    "model.eval()\n",
    "y_pred = model(x_train[:5])[0]\n",
    "y_pred = y_pred.detach().numpy()  # revert from tensor\n",
    "y_pred = y_pred.reshape(-1)  # reshape back to normal list\n",
    "print(\"sample prediction:  \", y_pred)\n",
    "\n",
    "y_train_sample = y_train[:5].detach().numpy().reshape(-1)\n",
    "print(\"sample true result: \", y_train_sample)\n",
    "\n",
    "# verify\n",
    "y_pred_round = [round(p) for p in y_pred]\n",
    "y_train_round = [round(p) for p in y_train_sample]\n",
    "\n",
    "# assert (y_pred_round == y_train_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a53fd75-b015-4544-a560-b208a4e4ce90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab4c8f7-628e-4b20-8492-679abc17b869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
